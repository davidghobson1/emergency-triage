{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6161cfe"
   },
   "source": [
    "## Neural Network Training - Pretrained Embedding Model with Dimension Reduction\n",
    "\n",
    "### Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "da086b43"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, concatenate, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_feats_filepath = \"~/scratch/datasets/yale_new_haven/training_test_sets/balanced_dataset/features/pretrained_embeddings/PubMedBERT/regression_nn/balanced_training_set.csv\"\n",
    "training_labels_filepath = \"~/scratch/datasets/yale_new_haven/training_test_sets/balanced_dataset/labels/yale_new_haven_balanced_training_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(training_feats_filepath)\n",
    "y_train = pd.read_csv(training_labels_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = X_train['ID'].astype('int32')\n",
    "X_train = X_train[[col for col in X_train if col != 'ID']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_cols = [col for col in X_train.columns if \"cc_\" in col]\n",
    "pmh_cols = [col for col in X_train.columns if \"pmh_\" in col]\n",
    "\n",
    "other_cols = [col for col in X_train.columns if col not in cc_cols and col not in pmh_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_original_embedding_size = len(cc_cols)\n",
    "pmh_original_embedding_size = len(pmh_cols)\n",
    "num_other_features = len(other_cols)\n",
    "\n",
    "# Chief complaint embedding\n",
    "cc_input = Input(shape=(cc_original_embedding_size, ), name='cc')\n",
    "cc_embedded_features = Dense(50, activation='relu')(cc_input)\n",
    "\n",
    "# Past Medical History embedding\n",
    "pmh_input = Input(shape=(pmh_original_embedding_size, ), name='pmh')\n",
    "pmh_embedded_features = Dense(50, activation='relu')(pmh_input)\n",
    "\n",
    "# Other features\n",
    "other_input = Input(shape=(num_other_features, ), name='other')\n",
    "\n",
    "# Merge all available features into a single large vector via concatenation\n",
    "x = concatenate([other_input, cc_embedded_features, pmh_embedded_features])\n",
    "\n",
    "dense_1 = Dense(512, activation='relu')(x)\n",
    "dropout_1 = Dropout(0.3)(dense_1)\n",
    "dense_2 = Dense(256, activation='relu')(dropout_1)\n",
    "dropout_2 = Dropout(0.2)(dense_2)\n",
    "output = Dense(1, activation='sigmoid', name='output')(dropout_2)\n",
    "\n",
    "# Instantiate an end-to-end model predicting both priority and department\n",
    "model = Model(\n",
    "    inputs=[other_input, cc_input, pmh_input],\n",
    "    outputs=output\n",
    ")\n",
    "\n",
    "binary_crossentropy = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(optimizer=\"adam\", loss=binary_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    {'other': X_train[other_cols], 'cc': X_train[cc_cols], 'pmh': X_train[pmh_cols]}, \n",
    "    {'output': y_train}, \n",
    "    epochs=10, \n",
    "    batch_size=64, \n",
    "    callbacks=[earlyStopping],\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate({'other': X_train[other_cols], 'cc': X_train[cc_cols], 'pmh': X_train[pmh_cols]}, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_filepath = \"/home/mila/d/david.hobson/scratch/models/balanced/experiments/pretrained/PubMedBERT/pretrained_embedding_reduced/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(nn_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Model Experiments - Hong.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
