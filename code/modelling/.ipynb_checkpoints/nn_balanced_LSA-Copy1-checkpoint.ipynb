{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6161cfe"
   },
   "source": [
    "## Neural Network Training - LSA\n",
    "### Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "da086b43"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_feats_filepath = \"~/scratch/datasets/yale_new_haven/training_test_sets/balanced_dataset/features/normalized_preprocessing/regression_nn/yale_new_haven_balanced_training_features.csv\"\n",
    "training_labels_filepath = \"~/scratch/datasets/yale_new_haven/training_test_sets/balanced_dataset/labels/yale_new_haven_balanced_training_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(training_feats_filepath)\n",
    "y_train = pd.read_csv(training_labels_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = X_train['ID'].astype('int32')\n",
    "X_train = X_train[[col for col in X_train if col != 'ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "disposition_var = {'disposition'}\n",
    "demographic_vars = {'age', 'gender', 'ethnicity', 'race', 'lang',\n",
    "       'religion', 'maritalstatus', 'employstatus', 'insurance_status'}\n",
    "triage_evaluation_vars = {'dep_name', 'esi', 'arrivalmode', 'arrivalmonth', 'arrivalday', 'arrivalhour_bin'}.union({col for col in X_train.columns if 'triage_vital' in col})\n",
    "chief_complaint_vars = {col for col in X_train.columns if \"cc_\" in col}\n",
    "medication_vars = {col for col in X_train.columns if 'meds_' in col}\n",
    "hospital_usage_stats_vars = {'previousdispo', 'n_edvisits', 'n_admissions', 'n_surgeries'}\n",
    "imaging_ekg_vars = {'cxr_count','echo_count','ekg_count','otherxr_count', 'otherus_count', 'headct_count', 'otherct_count', 'mri_count','otherimg_count'}\n",
    "historical_vital_vars = {'dbp_last',\n",
    " 'dbp_max',\n",
    " 'dbp_median',\n",
    " 'dbp_min',\n",
    " 'o2_device_last',\n",
    " 'o2_device_max',\n",
    " 'o2_device_median',\n",
    " 'o2_device_min',\n",
    " 'pulse_last',\n",
    " 'pulse_max',\n",
    " 'pulse_median',\n",
    " 'pulse_min',\n",
    " 'resp_last',\n",
    " 'resp_max',\n",
    " 'resp_median',\n",
    " 'resp_min',\n",
    " 'sbp_last',\n",
    " 'sbp_max',\n",
    " 'sbp_median',\n",
    " 'sbp_min',\n",
    " 'spo2_last',\n",
    " 'spo2_max',\n",
    " 'spo2_median',\n",
    " 'spo2_min',\n",
    " 'temp_last',\n",
    " 'temp_max',\n",
    " 'temp_median',\n",
    " 'temp_min'}\n",
    "curr = disposition_var.union(demographic_vars.union(triage_evaluation_vars.union(chief_complaint_vars.union(medication_vars.union(hospital_usage_stats_vars.union(imaging_ekg_vars.union(historical_vital_vars)))))))\n",
    "past_medical_hist_vars = {col for col in X_train.columns if col not in curr and \"_\" not in col and col not in ['ID', 'previousdispo']}\n",
    "\n",
    "cc_cols = list(chief_complaint_vars)\n",
    "pmh_cols = list(past_medical_hist_vars)\n",
    "\n",
    "cc_cols.sort()\n",
    "pmh_cols.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSA on the Chief Complaint and the Past Medical History columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_cc = TfidfTransformer()\n",
    "tfidf_pmh = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_long_features = tfidf_cc.fit_transform(X_train[cc_cols])\n",
    "pmh_long_features = tfidf_pmh.fit_transform(X_train[pmh_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "t_svd_cc = TruncatedSVD(k)\n",
    "t_svd_pmh = TruncatedSVD(k)\n",
    "\n",
    "cc_features = t_svd_cc.fit_transform(cc_long_features)\n",
    "pmh_features = t_svd_pmh.fit_transform(pmh_long_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc = pd.DataFrame(cc_features, columns=[f\"cc_{i}\" for i in range(k)])\n",
    "df_pmh = pd.DataFrame(cc_features, columns=[f\"pmh_{i}\" for i in range(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features = X_train[[col for col in X_train.columns if col not in cc_cols and col not in pmh_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([other_features, df_cc, df_pmh], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use binary_crossentropy = BinaryCrossentropy(from_logits=True) if model returns values in range [-inf, inf]\n",
    "# otherwise, model returns probabilities, then use from_logits=False (the default)\n",
    "binary_crossentropy = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential([\n",
    "    Dense(512, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model_1.compile(optimizer=\"adam\", loss=binary_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3505/3505 [==============================] - 18s 5ms/step - loss: 0.3663 - accuracy: 0.8362 - val_loss: 0.3495 - val_accuracy: 0.8445\n",
      "Epoch 2/10\n",
      "3505/3505 [==============================] - 16s 4ms/step - loss: 0.3483 - accuracy: 0.8460 - val_loss: 0.3390 - val_accuracy: 0.8504\n",
      "Epoch 3/10\n",
      "3505/3505 [==============================] - 16s 4ms/step - loss: 0.3430 - accuracy: 0.8488 - val_loss: 0.3366 - val_accuracy: 0.8503\n",
      "Epoch 4/10\n",
      "3505/3505 [==============================] - 16s 4ms/step - loss: 0.3393 - accuracy: 0.8512 - val_loss: 0.3304 - val_accuracy: 0.8544\n",
      "Epoch 5/10\n",
      "3505/3505 [==============================] - 16s 4ms/step - loss: 0.3367 - accuracy: 0.8524 - val_loss: 0.3404 - val_accuracy: 0.8484\n",
      "Epoch 6/10\n",
      "3505/3505 [==============================] - 15s 4ms/step - loss: 0.3346 - accuracy: 0.8530 - val_loss: 0.3303 - val_accuracy: 0.8539\n",
      "Epoch 7/10\n",
      "3505/3505 [==============================] - 16s 4ms/step - loss: 0.3330 - accuracy: 0.8542 - val_loss: 0.3285 - val_accuracy: 0.8558\n",
      "Epoch 8/10\n",
      "3505/3505 [==============================] - 16s 4ms/step - loss: 0.3325 - accuracy: 0.8542 - val_loss: 0.3277 - val_accuracy: 0.8553\n",
      "Epoch 9/10\n",
      "3505/3505 [==============================] - 15s 4ms/step - loss: 0.3314 - accuracy: 0.8549 - val_loss: 0.3274 - val_accuracy: 0.8567\n",
      "Epoch 10/10\n",
      "3505/3505 [==============================] - 16s 4ms/step - loss: 0.3299 - accuracy: 0.8558 - val_loss: 0.3314 - val_accuracy: 0.8566\n"
     ]
    }
   ],
   "source": [
    "history = model_1.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=10, \n",
    "    batch_size=64, \n",
    "    callbacks=[earlyStopping], \n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7788/7788 [==============================] - 15s 2ms/step - loss: 0.3234 - accuracy: 0.8606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32342734932899475, 0.8605650663375854]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_filepath = \"/home/mila/d/david.hobson/scratch/models/balanced/experiments/nn_LSA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mila/d/david.hobson/scratch/models/balanced/experiments/nn_LSA/assets\n"
     ]
    }
   ],
   "source": [
    "model_1.save(nn_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Model Experiments - Hong.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "yale_preprocessing",
   "language": "python",
   "name": "yale_preprocessing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
