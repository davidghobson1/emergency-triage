{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6161cfe"
   },
   "source": [
    "## Neural Network Training - Normalized Model with Reduction\n",
    "\n",
    "### Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "da086b43"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, concatenate, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_feats_filepath = \"yale_new_haven_balanced_training_features.csv\"\n",
    "training_labels_filepath = \"yale_new_haven_balanced_training_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(training_feats_filepath)\n",
    "y_train = pd.read_csv(training_labels_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = X_train['ID'].astype('int32')\n",
    "X_train = X_train[[col for col in X_train if col != 'ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_cols = [col for col in X_train.columns if \"cc_\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features = X_train[[col for col in X_train.columns if col not in cc_cols]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_original_embedding_size = len(cc_cols)\n",
    "num_other_features = other_features.shape[1]\n",
    "\n",
    "# Chief complaint embedding\n",
    "cc_input = Input(shape=(cc_original_embedding_size, ), name='cc')\n",
    "cc_embedded_features = Dense(50, activation='relu')(cc_input)\n",
    "\n",
    "# Other features\n",
    "other_input = Input(shape=(num_other_features, ), name='other')\n",
    "\n",
    "# Merge all available features into a single large vector via concatenation\n",
    "x = concatenate([other_input, cc_embedded_features])\n",
    "\n",
    "dense_1 = Dense(512, activation='relu')(x)\n",
    "dropout_1 = Dropout(0.3)(dense_1)\n",
    "dense_2 = Dense(256, activation='relu')(dropout_1)\n",
    "dropout_2 = Dropout(0.2)(dense_2)\n",
    "output = Dense(1, activation='sigmoid', name='output')(dropout_2)\n",
    "\n",
    "# Instantiate an end-to-end model predicting both priority and department\n",
    "model = Model(\n",
    "    inputs=[other_input, cc_input],\n",
    "    outputs=output\n",
    ")\n",
    "\n",
    "binary_crossentropy = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(optimizer=\"adam\", loss=binary_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    {'other': other_features, 'cc': X_train[cc_cols]}, \n",
    "    {'output': y_train}, \n",
    "    epochs=10, \n",
    "    batch_size=64, \n",
    "    callbacks=[earlyStopping],\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate({'other': other_features, 'cc': X_train[cc_cols]}, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_filepath = \"normalized_reduced/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(nn_filepath)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Model Experiments - Hong.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
