{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6161cfe"
   },
   "source": [
    "## Neural Network Training - Keras Embedding Model\n",
    "\n",
    "### Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "da086b43"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, GlobalAveragePooling1D, concatenate, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "from scipy.sparse import csc_matrix, save_npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_feats_filepath = \"yale_new_haven_balanced_training_features.csv\"\n",
    "training_labels_filepath = \"yale_new_haven_balanced_training_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(training_feats_filepath)\n",
    "y_train = pd.read_csv(training_labels_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = X_train['ID'].astype('int32')\n",
    "X_train = X_train[[col for col in X_train if col != 'ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disposition_var = {'disposition'}\n",
    "demographic_vars = {'age', 'gender', 'ethnicity', 'race', 'lang',\n",
    "       'religion', 'maritalstatus', 'employstatus', 'insurance_status'}\n",
    "triage_evaluation_vars = {'dep_name', 'esi', 'arrivalmode', 'arrivalmonth', 'arrivalday', 'arrivalhour_bin'}.union({col for col in X_train.columns if 'triage_vital' in col})\n",
    "chief_complaint_vars = {col for col in X_train.columns if \"cc_\" in col}\n",
    "medication_vars = {col for col in X_train.columns if 'meds_' in col}\n",
    "hospital_usage_stats_vars = {'previousdispo', 'n_edvisits', 'n_admissions', 'n_surgeries'}\n",
    "imaging_ekg_vars = {'cxr_count','echo_count','ekg_count','otherxr_count', 'otherus_count', 'headct_count', 'otherct_count', 'mri_count','otherimg_count'}\n",
    "historical_vital_vars = {'dbp_last',\n",
    " 'dbp_max',\n",
    " 'dbp_median',\n",
    " 'dbp_min',\n",
    " 'o2_device_last',\n",
    " 'o2_device_max',\n",
    " 'o2_device_median',\n",
    " 'o2_device_min',\n",
    " 'pulse_last',\n",
    " 'pulse_max',\n",
    " 'pulse_median',\n",
    " 'pulse_min',\n",
    " 'resp_last',\n",
    " 'resp_max',\n",
    " 'resp_median',\n",
    " 'resp_min',\n",
    " 'sbp_last',\n",
    " 'sbp_max',\n",
    " 'sbp_median',\n",
    " 'sbp_min',\n",
    " 'spo2_last',\n",
    " 'spo2_max',\n",
    " 'spo2_median',\n",
    " 'spo2_min',\n",
    " 'temp_last',\n",
    " 'temp_max',\n",
    " 'temp_median',\n",
    " 'temp_min'}\n",
    "curr = disposition_var.union(demographic_vars.union(triage_evaluation_vars.union(chief_complaint_vars.union(medication_vars.union(hospital_usage_stats_vars.union(imaging_ekg_vars.union(historical_vital_vars)))))))\n",
    "past_medical_hist_vars = {col for col in X_train.columns if col not in curr and \"_\" not in col and col not in ['ID', 'previousdispo']}\n",
    "\n",
    "cc_cols = list(chief_complaint_vars)\n",
    "pmh_cols = list(past_medical_hist_vars)\n",
    "\n",
    "cc_cols.sort()\n",
    "pmh_cols.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the sparse embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_sparse_features = scipy.sparse.load_npz('cc_embedding_training_input.npz')\n",
    "cc_features = pd.DataFrame(cc_sparse_features.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmh_sparse_features = scipy.sparse.load_npz('pmh_embedding_training_input.npz')\n",
    "pmh_features = pd.DataFrame(pmh_sparse_features.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features = X_train[[col for col in X_train.columns if col not in cc_cols and col not in pmh_cols]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len_cc = cc_features.shape[1]\n",
    "seq_len_pmh = pmh_features.shape[1]\n",
    "\n",
    "vocab_len_cc = cc_features.max().max() + 1\n",
    "vocab_len_pmh = pmh_features.max().max() + 1\n",
    "\n",
    "num_other_features = other_features.shape[1]\n",
    "\n",
    "# Chief complaint embedding\n",
    "cc_input = Input(shape=(seq_len_cc, ), name='cc')\n",
    "embedding_cc = Embedding(vocab_len_cc, 50, input_length=seq_len_cc)(cc_input)\n",
    "cc_embedded_features = GlobalAveragePooling1D()(embedding_cc)\n",
    "\n",
    "# Past Medical History embedding\n",
    "pmh_input = Input(shape=(seq_len_pmh, ), name='pmh')\n",
    "embedding_pmh = Embedding(vocab_len_pmh, 50, input_length=seq_len_pmh)(pmh_input)\n",
    "pmh_embedded_features = GlobalAveragePooling1D()(embedding_pmh)\n",
    "\n",
    "# Other features\n",
    "other_input = Input(shape=(num_other_features, ), name='other')\n",
    "\n",
    "# Merge all available features into a single large vector via concatenation\n",
    "x = concatenate([other_input, cc_embedded_features, pmh_embedded_features])\n",
    "\n",
    "dense_1 = Dense(512, activation='relu')(x)\n",
    "dropout_1 = Dropout(0.3)(dense_1)\n",
    "dense_2 = Dense(256, activation='relu')(dropout_1)\n",
    "dropout_2 = Dropout(0.2)(dense_2)\n",
    "output = Dense(1, activation='sigmoid', name='output')(dropout_2)\n",
    "\n",
    "# Instantiate an end-to-end model predicting both priority and department\n",
    "model = Model(\n",
    "    inputs=[other_input, cc_input, pmh_input],\n",
    "    outputs=output\n",
    ")\n",
    "\n",
    "binary_crossentropy = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(optimizer=\"adam\", loss=binary_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    {'other': other_features, 'cc': cc_features, 'pmh': pmh_features}, \n",
    "    {'output': y_train}, \n",
    "    epochs=50, \n",
    "    batch_size=64, \n",
    "    callbacks=[earlyStopping],\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate({'other': other_features, 'cc': cc_features, 'pmh': pmh_features}, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate({'other': other_features, 'cc': cc_features, 'pmh': pmh_features}, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_filepath = \"keras_embedding/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(nn_filepath)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Model Experiments - Hong.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
