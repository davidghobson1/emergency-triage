{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation of the Yale New Haven Dataset\n",
    "### Normalizing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pickle import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"~/scratch/datasets/yale_new_haven/yale_new_haven.csv\"\n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disposition_var = {'disposition'}\n",
    "\n",
    "demographic_vars = {'age', 'gender', 'ethnicity', 'race', 'lang',\n",
    "       'religion', 'maritalstatus', 'employstatus', 'insurance_status'}\n",
    "\n",
    "# department name, ESI score, arrival info, and triage vital info\n",
    "triage_evaluation_vars = {'dep_name', 'esi', 'arrivalmode', 'arrivalmonth', 'arrivalday', 'arrivalhour_bin'}.union({col for col in df.columns if 'triage_vital' in col})\n",
    "\n",
    "# chief complaint info (only top 200 were included; represents >90% of the complaints)\n",
    "chief_complaint_vars = {col for col in df.columns if \"cc_\" in col}\n",
    "\n",
    "# medication info\n",
    "medication_vars = {col for col in df.columns if 'meds_' in col}\n",
    "\n",
    "hospital_usage_stats_vars = {'previousdispo', 'n_edvisits', 'n_admissions', 'n_surgeries'}\n",
    "\n",
    "# prior imaging and EKG counts\n",
    "# chest x-ray, echocardiogram, electrocardiogram (EKG), other x-ray, other ultra-sound, head CT, other CT, MRI, and all other imaging\n",
    "imaging_ekg_vars = {'cxr_count','echo_count','ekg_count','otherxr_count', 'otherus_count', 'headct_count', 'otherct_count', 'mri_count','otherimg_count'}\n",
    "\n",
    "# historic vitals include: systolic blood pressure, diastolic blood pressure, pulse, respiratory rate, oxygen saturation, presence of oxygen device, and temperature\n",
    "historical_vital_vars = {'dbp_last',\n",
    " 'dbp_max',\n",
    " 'dbp_median',\n",
    " 'dbp_min',\n",
    " 'o2_device_last',\n",
    " 'o2_device_max',\n",
    " 'o2_device_median',\n",
    " 'o2_device_min',\n",
    " 'pulse_last',\n",
    " 'pulse_max',\n",
    " 'pulse_median',\n",
    " 'pulse_min',\n",
    " 'resp_last',\n",
    " 'resp_max',\n",
    " 'resp_median',\n",
    " 'resp_min',\n",
    " 'sbp_last',\n",
    " 'sbp_max',\n",
    " 'sbp_median',\n",
    " 'sbp_min',\n",
    " 'spo2_last',\n",
    " 'spo2_max',\n",
    " 'spo2_median',\n",
    " 'spo2_min',\n",
    " 'temp_last',\n",
    " 'temp_max',\n",
    " 'temp_median',\n",
    " 'temp_min'}\n",
    "\n",
    "curr = disposition_var.union(demographic_vars.union(triage_evaluation_vars.union(chief_complaint_vars.union(medication_vars.union(hospital_usage_stats_vars.union(imaging_ekg_vars.union(historical_vital_vars)))))))\n",
    "\n",
    "# past medical history\n",
    "past_medical_hist_vars = {col for col in df.columns if col not in curr and \"_\" not in col and col not in ['ID', 'previousdispo']}\n",
    "\n",
    "curr = curr.union(past_medical_hist_vars)\n",
    "\n",
    "# historical labs ordered by ED (only top 150 comprising of 94% of all orders)\n",
    "historical_lab_vars = {col for col in df.columns if col not in curr and col not in 'ID'}\n",
    "\n",
    "# print(f\"Response: {len(disposition_var)}\")\n",
    "# print(f\"Demographics: {len(demographic_vars)}\")\n",
    "# print(f\"Triage evaluation: {len(triage_evaluation_vars)}\")\n",
    "# print(f\"Chief Complaint: {len(chief_complaint_vars)}\")\n",
    "# print(f\"Hospital Usage Statistics: {len(hospital_usage_stats_vars)}\")\n",
    "# print(f\"Past Medical History: {len(past_medical_hist_vars)}\")\n",
    "# print(f\"Medications: {len(medication_vars)}\")\n",
    "# print(f\"Historical Vitals: {len(historical_vital_vars)}\")\n",
    "# print(f\"Historical Labs: {len(historical_lab_vars)}\")\n",
    "# print(f\"Imaging/EKG counts: {len(imaging_ekg_vars)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix some issues with the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N/A and other value fixes\n",
    "# - race column has both nan and unknown -> change to just unknown\n",
    "# - some patients have no entered chief complaints (all the chief complaints are N/A), give them all 0's\n",
    "fillna_values = {'race': 'Unknown'}\n",
    "chief_complaint_vars = {col for col in df.columns if \"cc_\" in col}\n",
    "fillna_values.update({cc: 0 for cc in list(chief_complaint_vars)})\n",
    "df = df.fillna(fillna_values)\n",
    "\n",
    "# change ESI feature to string so it becomes categorical\n",
    "# same with the O2 device features since these indicate the presence or absence of a O2 device which can be null (not known)\n",
    "cate_float_feats = ['esi', 'triage_vital_o2_device', 'o2_device_last', 'o2_device_min', 'o2_device_max', 'o2_device_median']\n",
    "df = df.astype({feat: str for feat in cate_float_feats})\n",
    "\n",
    "# any chief complaint with number higher than 1, make as 1 (complaints are supposed to be binary)\n",
    "for cc in chief_complaint_vars:\n",
    "    df.loc[df[cc] > 1, cc] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the datatypes for downstream processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all int features to floats for easier processing\n",
    "# and for better memory use\n",
    "df = df.astype({col: 'float32' for col in df[df.select_dtypes(include=['float64', 'int64']).columns]})\n",
    "# chief complaint and past medical history features should be ints, since they are already encoded \n",
    "# and don't need to be processed\n",
    "df = df.astype({col: 'int32' for col in list(chief_complaint_vars.union(past_medical_hist_vars))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an ID feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the original index as the ID; store as an int, so it can pass through the ColumnTransformer\n",
    "df.rename_axis('ID', inplace=True)\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature and Label Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set features and label columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = 'disposition'\n",
    "\n",
    "# ignore these features since they contain only NaN values, or because of the provided note\n",
    "useless_feats = [\n",
    "    'phencyclidine(pcp)screen,urine,noconf._last',\n",
    "    'phencyclidine(pcp)screen,urine,noconf._min', \n",
    "    'phencyclidine(pcp)screen,urine,noconf._max', \n",
    "    'phencyclidine(pcp)screen,urine,noconf._median',\n",
    "    'benzodiazepinesscreen,urine,noconf._last',       # only one person in the dataset has a non-nan value\n",
    "    'ecodesmachinery'                                 # only 0 values\n",
    "]\n",
    "# other columns we may want to ignore\n",
    "other_ignore_cols = []    \n",
    "\n",
    "ignore_cols = useless_feats + [label_col] + other_ignore_cols\n",
    "\n",
    "features = [col for col in df.columns if col not in ignore_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "\n",
    "# use the same training/test split as in the standarization dataset\n",
    "# therefore use those labels\n",
    "# y = LabelEncoder().fit_transform(df[label_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and test sets\n",
    "\n",
    "10% split as per Hong *et al.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training and test IDs from the previous experiments (for more direct accurate comparisons) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = pd.read_csv('~/scratch/datasets/yale_new_haven/training_test_sets/full_dataset/training_idxs.csv', header=None).squeeze('columns')\n",
    "test_ids = pd.read_csv('~/scratch/datasets/yale_new_haven/training_test_sets/full_dataset/test_idxs.csv', header=None).squeeze('columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.loc[train_ids]\n",
    "X_test = X.loc[test_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview:\n",
    "- Floats need normalizing and imputing to median\n",
    "- Objects need one-hot encoding and imputing to missing\n",
    "\n",
    "- Chief complaints and Past Medical History are already one-hot encoded (leave as-is)\n",
    "\n",
    "Details:\n",
    "- Impute\n",
    "    - Missing numerics are equated to median of values\n",
    "    - Missing categories are equated to 'Missing'\n",
    "    - Done before standardization to not mess with the scaling in standardization\n",
    "- One Hot Encode \n",
    "    - only for categorical\n",
    "    - binary categoricals are encoded as one feature\n",
    "    - all other categories are encoded as n features\n",
    "- Normalize\n",
    "    - only for floats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define pipelines for feature processing\n",
    "\n",
    "(Impute, one hot encode, and normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline transformation for numerical features\n",
    "pipe_floats = Pipeline(\n",
    "    steps=[\n",
    "        ('impute (floats)', SimpleImputer(strategy='median', copy=False)),\n",
    "        ('normalize (floats)', MinMaxScaler())\n",
    "    ], \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# pipeline transformation for categorical features\n",
    "pipe_category = Pipeline(\n",
    "    steps=[\n",
    "        ('impute (categoric)', SimpleImputer(strategy='constant', fill_value = 'Missing')),\n",
    "        ('one hot encode', OneHotEncoder(drop='if_binary')),\n",
    "    ], \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer(\n",
    "    [\n",
    "        ('categoric', pipe_category, make_column_selector(dtype_include='object')),\n",
    "        ('floats', pipe_floats, make_column_selector(dtype_include='float')),\n",
    "    ],\n",
    "    remainder='passthrough', verbose_feature_names_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the transformer and transform the training set\n",
    "X_t = column_transformer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the transformed training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pd.DataFrame(X_t, columns=column_transformer.get_feature_names_out()).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(k.memory_usage(deep=True))/(1024**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"~/scratch/datasets/yale_new_haven/training_test_sets/full_dataset/features/normalized_preprocessing/regression_nn/yale_new_haven_training_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = column_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2 = pd.DataFrame(X_t, columns=column_transformer.get_feature_names_out()).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename =  '~/scratch/datasets/yale_new_haven/training_test_sets/full_dataset/features/normalized_preprocessing/regression_nn/yale_new_haven_test_features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
