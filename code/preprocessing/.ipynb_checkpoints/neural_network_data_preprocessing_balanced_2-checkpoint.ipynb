{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation of the Yale New Haven Dataset - Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pickle import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"~/scratch/datasets/yale_new_haven/yale_new_haven.csv\"\n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 1\n",
      "Demographics: 9\n",
      "Triage evaluation: 13\n",
      "Chief Complaint: 200\n",
      "Hospital Usage Statistics: 4\n",
      "Past Medical History: 281\n",
      "Medications: 48\n",
      "Historical Vitals: 28\n",
      "Historical Labs: 379\n",
      "Imaging/EKG counts: 9\n"
     ]
    }
   ],
   "source": [
    "disposition_var = {'disposition'}\n",
    "\n",
    "demographic_vars = {'age', 'gender', 'ethnicity', 'race', 'lang',\n",
    "       'religion', 'maritalstatus', 'employstatus', 'insurance_status'}\n",
    "\n",
    "# department name, ESI score, arrival info, and triage vital info\n",
    "triage_evaluation_vars = {'dep_name', 'esi', 'arrivalmode', 'arrivalmonth', 'arrivalday', 'arrivalhour_bin'}.union({col for col in df.columns if 'triage_vital' in col})\n",
    "\n",
    "# chief complaint info (only top 200 were included; represents >90% of the complaints)\n",
    "chief_complaint_vars = {col for col in df.columns if \"cc_\" in col}\n",
    "\n",
    "# medication info\n",
    "medication_vars = {col for col in df.columns if 'meds_' in col}\n",
    "\n",
    "hospital_usage_stats_vars = {'previousdispo', 'n_edvisits', 'n_admissions', 'n_surgeries'}\n",
    "\n",
    "# prior imaging and EKG counts\n",
    "# chest x-ray, echocardiogram, electrocardiogram (EKG), other x-ray, other ultra-sound, head CT, other CT, MRI, and all other imaging\n",
    "imaging_ekg_vars = {'cxr_count','echo_count','ekg_count','otherxr_count', 'otherus_count', 'headct_count', 'otherct_count', 'mri_count','otherimg_count'}\n",
    "\n",
    "# historic vitals include: systolic blood pressure, diastolic blood pressure, pulse, respiratory rate, oxygen saturation, presence of oxygen device, and temperature\n",
    "historical_vital_vars = {'dbp_last',\n",
    " 'dbp_max',\n",
    " 'dbp_median',\n",
    " 'dbp_min',\n",
    " 'o2_device_last',\n",
    " 'o2_device_max',\n",
    " 'o2_device_median',\n",
    " 'o2_device_min',\n",
    " 'pulse_last',\n",
    " 'pulse_max',\n",
    " 'pulse_median',\n",
    " 'pulse_min',\n",
    " 'resp_last',\n",
    " 'resp_max',\n",
    " 'resp_median',\n",
    " 'resp_min',\n",
    " 'sbp_last',\n",
    " 'sbp_max',\n",
    " 'sbp_median',\n",
    " 'sbp_min',\n",
    " 'spo2_last',\n",
    " 'spo2_max',\n",
    " 'spo2_median',\n",
    " 'spo2_min',\n",
    " 'temp_last',\n",
    " 'temp_max',\n",
    " 'temp_median',\n",
    " 'temp_min'}\n",
    "\n",
    "curr = disposition_var.union(demographic_vars.union(triage_evaluation_vars.union(chief_complaint_vars.union(medication_vars.union(hospital_usage_stats_vars.union(imaging_ekg_vars.union(historical_vital_vars)))))))\n",
    "\n",
    "# past medical history\n",
    "past_medical_hist_vars = {col for col in df.columns if col not in curr and \"_\" not in col and col not in ['ID', 'previousdispo']}\n",
    "\n",
    "curr = curr.union(past_medical_hist_vars)\n",
    "\n",
    "# historical labs ordered by ED (only top 150 comprising of 94% of all orders)\n",
    "historical_lab_vars = {col for col in df.columns if col not in curr and col not in 'ID'}\n",
    "\n",
    "print(f\"Response: {len(disposition_var)}\")\n",
    "print(f\"Demographics: {len(demographic_vars)}\")\n",
    "print(f\"Triage evaluation: {len(triage_evaluation_vars)}\")\n",
    "print(f\"Chief Complaint: {len(chief_complaint_vars)}\")\n",
    "print(f\"Hospital Usage Statistics: {len(hospital_usage_stats_vars)}\")\n",
    "print(f\"Past Medical History: {len(past_medical_hist_vars)}\")\n",
    "print(f\"Medications: {len(medication_vars)}\")\n",
    "print(f\"Historical Vitals: {len(historical_vital_vars)}\")\n",
    "print(f\"Historical Labs: {len(historical_lab_vars)}\")\n",
    "print(f\"Imaging/EKG counts: {len(imaging_ekg_vars)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix some issues with the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N/A and other value fixes\n",
    "# - race column has both nan and unknown -> change to just unknown\n",
    "# - some patients have no entered chief complaints (all the chief complaints are N/A), give them all 0's\n",
    "fillna_values = {'race': 'Unknown'}\n",
    "chief_complaint_vars = {col for col in df.columns if \"cc_\" in col}\n",
    "fillna_values.update({cc: 0 for cc in list(chief_complaint_vars)})\n",
    "df = df.fillna(fillna_values)\n",
    "\n",
    "# change ESI feature to string so it becomes categorical\n",
    "# same with the O2 device features since these indicate the presence or absence of a O2 device which can be null (not known)\n",
    "cate_float_feats = ['esi', 'triage_vital_o2_device', 'o2_device_last', 'o2_device_min', 'o2_device_max', 'o2_device_median']\n",
    "df = df.astype({feat: str for feat in cate_float_feats})\n",
    "\n",
    "# any chief complaint with number higher than 1, make as 1 (complaints are supposed to be binary)\n",
    "for cc in chief_complaint_vars:\n",
    "    df.loc[df[cc] > 1, cc] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the datatypes for downstream processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all int features to floats for easier processing\n",
    "df = df.astype({col: 'float64' for col in df[df.select_dtypes(include=['int64']).columns]})\n",
    "# chief complaint and past medical history features should be ints, since they are already encoded \n",
    "# and don't need to be processed\n",
    "df = df.astype({col: 'int64' for col in list(chief_complaint_vars.union(past_medical_hist_vars))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an ID feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the original index as the ID; store as an int, so it can pass through the ColumnTransformer\n",
    "df.rename_axis('ID', inplace=True)\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create balanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the senior and adults indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senior_idxs = df[df['age'] >= 65].index\n",
    "adult_idxs = df[df['age'] < 65].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a random sample of the adult DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = df.loc[adult_idxs].sample(n=len(senior_idxs))\n",
    "# sort the dataframe by its index\n",
    "df_a = df_a.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pd.concat([df_a, df.loc[senior_idxs]]).sort_index()\n",
    "df = df_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature and Label Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set features and label columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = 'disposition'\n",
    "\n",
    "# ignore these features since they contain only NaN values, or because of the provided note\n",
    "useless_feats = [\n",
    "    'phencyclidine(pcp)screen,urine,noconf._last',\n",
    "    'phencyclidine(pcp)screen,urine,noconf._min', \n",
    "    'phencyclidine(pcp)screen,urine,noconf._max', \n",
    "    'phencyclidine(pcp)screen,urine,noconf._median',\n",
    "    'benzodiazepinesscreen,urine,noconf._last',       # only one person in the dataset has a non-nan value\n",
    "    'ecodesmachinery'                                 # only 0 values\n",
    "]\n",
    "# other columns we may want to ignore\n",
    "other_ignore_cols = []    \n",
    "\n",
    "ignore_cols = useless_feats + [label_col] + other_ignore_cols\n",
    "\n",
    "features = [col for col in df.columns if col not in ignore_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = LabelEncoder().fit_transform(df[label_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that the labels correspond to 0 - discharge, 1 - admittance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (df[label_col].iloc[0] == 'Discharge' and y[0] == 1) or (df[label_col].iloc[0] == 'Admit' and y[0] == 0):\n",
    "    y = np.array([0 if y_i == 1 else 1 for y_i in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and test sets\n",
    "\n",
    "10% split as per Hong *et al.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview:\n",
    "- Floats need normalizing and imputing to median\n",
    "- Objects need one-hot encoding and imputing to missing\n",
    "\n",
    "- Chief complaints and Past Medical History are already one-hot encoded (leave as-is)\n",
    "\n",
    "Details:\n",
    "- Impute\n",
    "    - Missing numerics are equated to median of values\n",
    "    - Missing categories are equated to 'Missing'\n",
    "    - Done before standardization to not mess with the scaling in standardization\n",
    "- One Hot Encode \n",
    "    - only for categorical\n",
    "    - binary categoricals are encoded as one feature\n",
    "    - all other categories are encoded as n features\n",
    "- Normalize\n",
    "    - only for floats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define pipelines for feature processing\n",
    "\n",
    "(Impute, one hot encode, and normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline transformation for numerical features\n",
    "pipe_floats = Pipeline(\n",
    "    steps=[\n",
    "        ('impute (floats)', SimpleImputer(strategy='median', copy=False)),\n",
    "        ('normalize (floats)', MaxMinScaler())\n",
    "    ], \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# pipeline transformation for categorical features\n",
    "pipe_category = Pipeline(\n",
    "    steps=[\n",
    "        ('impute (categoric)', SimpleImputer(strategy='constant', fill_value = 'Missing')),\n",
    "        ('one hot encode', OneHotEncoder(drop='if_binary')),\n",
    "    ], \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer(\n",
    "    [\n",
    "        ('categoric', pipe_category, make_column_selector(dtype_include='object')),\n",
    "        ('floats', pipe_floats, make_column_selector(dtype_include='float')),\n",
    "    ],\n",
    "    remainder='passthrough', verbose_feature_names_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline]  (step 1 of 3) Processing impute (categoric), total=   0.5s\n",
      "[Pipeline] .... (step 2 of 3) Processing one hot encode, total=   2.5s\n",
      "[Pipeline]  (step 3 of 3) Processing standardize (categoric), total=   0.4s\n",
      "[Pipeline] ... (step 1 of 2) Processing impute (floats), total=  25.1s\n",
      "[Pipeline]  (step 2 of 2) Processing standardize (floats), total=   3.4s\n"
     ]
    }
   ],
   "source": [
    "# fit the transformer and transform the training set\n",
    "X_t = column_transformer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the transformed training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pd.DataFrame(X_t, columns=column_transformer.get_feature_names_out()).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"~/scratch/datasets/yale_new_haven/training_test_sets/balanced_split/features/yale_new_haven_balanced_training_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform half of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t_test = column_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2 = pd.DataFrame(X_t_test, columns=column_transformer.get_feature_names_out()).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"~/scratch/datasets/yale_new_haven/training_test_sets/balanced_split/features/yale_new_haven_balanced_test_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"~/scratch/datasets/yale_new_haven/training_test_sets/balanced_split/labels/yale_new_haven_balanced_training_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"~/scratch/datasets/yale_new_haven/training_test_sets/balanced_split/labels/yale_new_haven_balanced_test_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yale_preprocessing",
   "language": "python",
   "name": "yale_preprocessing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
