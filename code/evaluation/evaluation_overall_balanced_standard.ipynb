{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6161cfe"
   },
   "source": [
    "## Model Evaluation - Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "da086b43"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import DMatrix\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, RocCurveDisplay, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "import pickle\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression and neural network\n",
    "test_feats_file = \"~/scratch/datasets/yale_new_haven/training_test_sets/full_dataset/features/normalized_preprocessing/regression_nn/yale_new_haven_test_features.csv\"\n",
    "# xgboost\n",
    "test_feats_xgb_file = \"~/scratch/datasets/yale_new_haven/training_test_sets/full_dataset/features/normalized_preprocessing/xgboost/yale_new_haven_test_features_xgb.csv\"\n",
    "# test labels\n",
    "test_labels_file = \"~/scratch/datasets/yale_new_haven/training_test_sets/full_dataset/labels/full_dataset_test_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(test_feats_file)\n",
    "X_test_xgb = pd.read_csv(test_feats_xgb_file)\n",
    "y_test = pd.read_csv(test_labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = X_test['ID'].astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[[col for col in X_test.columns if col != 'ID']]\n",
    "X_test_xgb = X_test_xgb[[col for col in X_test_xgb.columns if col != 'ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the DMatrix for XGBoost\n",
    "dtest = DMatrix(X_test_xgb, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_filepath = \"/home/mila/d/david.hobson/scratch/models/full/logistic_regresion_full.joblib\"\n",
    "nn_filepath = \"/home/mila/d/david.hobson/scratch/models/full/neural_network_full\"\n",
    "xgb_filepath = \"/home/mila/d/david.hobson/scratch/models/full/xgboost_full.ubj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'tree_method': 'hist',   # tree construction algorithm, 'hist' and 'gpu_hist' are recommended for large datasets\n",
    "\n",
    "    # parameters Hong used\n",
    "    'eta': 0.3,                              # learning rate\n",
    "    'nthread': 5,                            # maximum number of threads to run simulateously\n",
    "    'eval_metric': 'auc',                    # evaluation metric\n",
    "    'objective': 'binary:logistic',          # objective function\n",
    "\n",
    "    # parameters Hong optimized for\n",
    "    'max_depth': 20,                         # max depth of the tree\n",
    "    'colsample_bylevel': 0.05,               # subsample ratio of columns at each level. Subsampling occurs once for every new depth level reached in a tree. Columns are subsampled from the set of columns chosen for the current tree.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = load(lr_filepath)\n",
    "nn_model = load_model(nn_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.Booster(xgb_params)  # init model\n",
    "xgb_model.load_model(xgb_filepath)  # load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZB_sSdeZsrlf"
   },
   "source": [
    "### Test set probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28XTcTzOd2rC",
    "outputId": "faa72563-f7e2-4ed9-c8d4-e00a485092a0"
   },
   "outputs": [],
   "source": [
    "lr_acc = lr_clf.score(X_test, y_test)\n",
    "nn_loss, nn_acc = nn_model.evaluate(X_test, y_test)\n",
    "xgb_acc = accuracy_score(y_test, np.round(xgb_model.predict(dtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test Accuracy:\\n\\tLogistic Regression: {np.round(lr_acc*100, 2)}\\n\\tNeural Network: {np.round(nn_acc*100, 2)}\\n\\tXGBoost: {np.round(xgb_acc*100, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rilAFFLyvATB"
   },
   "source": [
    "## AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_lgpuob1CYW",
    "outputId": "bc6a68bb-803a-4944-d1fb-6a38b41e9e9b"
   },
   "outputs": [],
   "source": [
    "# for binary case, you give function the probabilities of the items being in the \"1\" class\n",
    "# or you can pass clf.decision_function(X_test)\n",
    "# roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hong: AUROC = 0.91\n",
    "lr_auroc = roc_auc_score(y_test, lr_clf.predict_proba(X_test)[:, 1])\n",
    "nn_auroc = roc_auc_score(y_test, nn_model.predict(X_test))\n",
    "xgb_auroc = roc_auc_score(y_test, xgb_model.predict(dtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test AUROC:\\n\\tLogistic Regression: {np.round(lr_auroc*100, 2)}\\n\\tNeural Network: {np.round(nn_auroc*100, 2)}\\n\\tXGBoost: {np.round(xgb_auroc*100,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "dco736ql1JbC",
    "outputId": "a5386ad8-ee8f-4b54-85d3-505ec6801620"
   },
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_predictions(y_test, lr_clf.decision_function(X_test))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_predictions(y_test, nn_model.predict(X_test))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_predictions(y_test, xgb_model.predict(dtest))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seniors vs. Adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senior_idxs_filename = \"/home/mila/d/david.hobson/scratch/datasets/yale_new_haven/demographic_indices/age_65_and_over.pickle\"\n",
    "adult_idxs_filename = \"/home/mila/d/david.hobson/scratch/datasets/yale_new_haven/demographic_indices/age_less_than_65.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices of patients 65 and older\n",
    "with open(senior_idxs_filename, 'rb') as f:\n",
    "    senior_idxs = pickle.load(f)\n",
    "    \n",
    "with open(adult_idxs_filename, 'rb') as f:\n",
    "    adult_idxs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seniors_test = test_ids[test_ids.isin(senior_idxs)].index\n",
    "adults_test = test_ids[~test_ids.isin(senior_idxs)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest_seniors = DMatrix(X_test_xgb.loc[seniors_test], y_test.loc[seniors_test])\n",
    "dtest_adults = DMatrix(X_test_xgb.loc[adults_test], y_test.loc[adults_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seniors vs. Adults Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_acc_seniors = lr_clf.score(X_test.loc[seniors_test], y_test.loc[seniors_test])\n",
    "lr_acc_adults = lr_clf.score(X_test.loc[adults_test], y_test.loc[adults_test])\n",
    "\n",
    "nn_loss_seniors, nn_acc_seniors = nn_model.evaluate(X_test.loc[seniors_test], y_test.loc[seniors_test])\n",
    "nn_loss_adults, nn_acc_adults = nn_model.evaluate(X_test.loc[adults_test], y_test.loc[adults_test])\n",
    "\n",
    "xgb_acc_seniors = accuracy_score(y_test.loc[seniors_test], np.round(xgb_model.predict(dtest_seniors)))\n",
    "xgb_acc_adults = accuracy_score(y_test.loc[adults_test], np.round(xgb_model.predict(dtest_adults)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Training set:\\n\\tAdults score: {np.round(adult_score_train*100, 2)}\\n\\tSeniors score: {np.round(senior_score_train*100, 2)}\")\n",
    "print(\"Test Accuracy\")\n",
    "print()\n",
    "print(f\"Logistic Regression:\\n\\tAdults score: {np.round(lr_acc_adults*100, 2)} (n = {len(adults_test)})\\n\\tSeniors score: {np.round(lr_acc_seniors*100, 2)} (n = {len(seniors_test)})\")\n",
    "print()\n",
    "print(f\"Neural Network:\\n\\tAdults score: {np.round(nn_acc_adults*100, 2)} (n = {len(adults_test)})\\n\\tSeniors score: {np.round(nn_acc_seniors*100, 2)} (n = {len(seniors_test)})\")\n",
    "print()\n",
    "print(f\"XGBoost:\\n\\tAdults score: {np.round(xgb_acc_adults*100, 2)} (n = {len(adults_test)})\\n\\tSeniors score: {np.round(xgb_acc_seniors*100, 2)} (n = {len(seniors_test)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr_clf.predict(X_test)\n",
    "\n",
    "y_pred_lr_seniors = lr_clf.predict(X_test.loc[seniors_test])\n",
    "y_pred_lr_adults = lr_clf.predict(X_test.loc[adults_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nn = np.round(nn_model.predict(X_test))\n",
    "\n",
    "y_pred_nn_seniors = np.round(nn_model.predict(X_test.loc[seniors_test]))\n",
    "y_pred_nn_adults = np.round(nn_model.predict(X_test.loc[adults_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = np.round(xgb_model.predict(dtest))\n",
    "\n",
    "y_pred_xgb_seniors = np.round(xgb_model.predict(dtest_seniors))\n",
    "y_pred_xgb_adults = np.round(xgb_model.predict(dtest_adults))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 'all'\n",
    "\n",
    "print(\"Overall\")\n",
    "print('\\tLogistic Regression')\n",
    "print('\\tNeural Network')\n",
    "print(\"\\tXGBoost\")\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_lr, normalize=norm)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_nn, normalize=norm)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_xgb, normalize=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seniors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 'pred'\n",
    "\n",
    "print('Seniors')\n",
    "print('\\tLogistic Regression')\n",
    "print('\\tNeural Network')\n",
    "print('\\tXGBoost')\n",
    "ConfusionMatrixDisplay.from_predictions(y_test.loc[seniors_test], y_pred_lr_seniors, normalize=norm)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test.loc[seniors_test], y_pred_nn_seniors, normalize=norm)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test.loc[seniors_test], y_pred_xgb_seniors, normalize=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 'all'\n",
    "\n",
    "print(\"Adults\")\n",
    "print('\\tLogistic Regression')\n",
    "print('\\tNeural Network')\n",
    "print('\\tXGBoost')\n",
    "ConfusionMatrixDisplay.from_predictions(y_test.loc[adults_test], y_pred_lr_adults, normalize=norm)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test.loc[adults_test], y_pred_nn_adults, normalize=norm)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test.loc[adults_test], y_pred_xgb_adults, normalize=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_type = 'gain'       # average gain of splits which use the feature   \n",
    "max_num_features = 15\n",
    "\n",
    "xgb.plot_importance(xgb_model, importance_type=importance_type, max_num_features=max_num_features)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Model Experiments - Hong.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
